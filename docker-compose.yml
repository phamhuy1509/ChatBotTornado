services:
  backend:
    build:
      context: ./Backend
      dockerfile: ./backend.dockerfile
    ports:
      - 6886:6886
    networks:
      chatbot_tornado:
        ipv4_address: 172.38.0.2
  frontend:
    build:
      context: ./Frontend
      dockerfile: ./frontend.dockerfile
    ports:
      - 6885:6885
    depends_on:
      - backend
    networks:
      chatbot_tornado:
        ipv4_address: 172.38.0.3
  nginx:
    image: nginx:latest
    ports:
      - 80:80
    expose:
      - 80
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - backend
      - frontend
    networks:
      chatbot_tornado:
        ipv4_address: 172.38.0.4
  tgi:
    image: ghcr.io/huggingface/text-generation-inference:2.0
    ports:
      - 6884:80
    expose:
      - 6884
    volumes:
      - /home/duchuy/data_tgi:/data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    shm_size: 4g
    environment:
      - MODEL_ID=TheBloke/deepseek-coder-6.7B-base-AWQ
      - QUANTIZE=awq
      - MAX_INPUT_LENGTH=1024
      - MAX_TOTAL_TOKENS=1280
      - MAX_BATCH_PREFILL_TOKENS=1280
      - PORT=6884
    networks:
      chatbot_tornado:
        ipv4_address: 172.38.0.5
networks:
  chatbot_tornado:
    external: true
    name: chatbot_tornado
    